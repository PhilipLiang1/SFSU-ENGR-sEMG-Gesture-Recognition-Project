{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# upload local files to google colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "YGI215e-5cG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alp8-xGgXDpK"
      },
      "outputs": [],
      "source": [
        "# Classification\n",
        "  # imports and constants\n",
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "#from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import io\n",
        "\n",
        "# constants; types of flowers\n",
        "#CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
        "#SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "FEATURE_NAMES = ['MAV0', 'ZC0', 'WL0', 'T0','MAV1', 'ZC1', 'WL1', 'T1', \n",
        "                 'MAV2','ZC2', 'WL2', 'T2', 'MAV3', 'ZC3', 'WL3', 'T3', 'Gestures']\n",
        "\n",
        "GESTURES = ['Rest', 'HandClose', 'HandOpen', 'PointIndex', 'DevilHorns']\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we use keras (a module inside of TensorFlow) to grab our flowers datasets and read them into a pandas dataframe\n",
        "#train_path = tf.keras.utils.get_file(\n",
        " #   \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
        "#test_path = tf.keras.utils.get_file(\n",
        "#    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
        "\n",
        "\n",
        "# will use this to load in the data files from local pc\n",
        "rest_feat_df = pd.read_csv(io.BytesIO(uploaded['Rest.csv']))\n",
        "rest1_feat_df = pd.read_csv(io.BytesIO(uploaded['Rest1.csv']))\n",
        "handclose_feat_df = pd.read_csv(io.BytesIO(uploaded['HandClose.csv']))\n",
        "handclose1_feat_df = pd.read_csv(io.BytesIO(uploaded['HandClose1.csv']))\n",
        "handopen_feat_df = pd.read_csv(io.BytesIO(uploaded['HandOpen.csv']))\n",
        "handopen1_feat_df = pd.read_csv(io.BytesIO(uploaded['HandOpen1.csv']))\n",
        "pointindex_feat_df = pd.read_csv(io.BytesIO(uploaded['PointIndex.csv']))\n",
        "pointindex1_feat_df = pd.read_csv(io.BytesIO(uploaded['PointIndex1.csv']))\n",
        "devilhorns_feat_df = pd.read_csv(io.BytesIO(uploaded['DevilHorns.csv']))\n",
        "devilhorns1_feat_df = pd.read_csv(io.BytesIO(uploaded['DevilHorns1.csv']))\n",
        "\n",
        "#df = pd.read_csv(\"HandFlex3.txt\", sep=',', names=CSV_COLUMN_NAMES, header=0)\n",
        "#df.head()\n",
        "#X = df.iloc[:,1:].copy()\n",
        "#print(X)\n",
        "#target = df['Species'].copy()\n",
        "#print(target)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X,target,test_size=0.3,random_state=0)\n",
        "\n",
        "#X = df.iloc[:,:4].copy()\n",
        "\n",
        "# will use this to create a feature matrix that stacks all the gesture files together\n",
        "feat_matrix = np.vstack([rest_feat_df.to_numpy(), rest1_feat_df.to_numpy(), \n",
        "                handclose_feat_df.to_numpy(), handclose1_feat_df.to_numpy(),\n",
        "                handopen_feat_df.to_numpy(), handopen1_feat_df.to_numpy(), \n",
        "                pointindex_feat_df.to_numpy(), pointindex1_feat_df.to_numpy(),\n",
        "                devilhorns_feat_df.to_numpy(), devilhorns1_feat_df.to_numpy()])\n",
        "\n",
        "feat_matrix_df = pd.DataFrame(feat_matrix)\n",
        "feat_matrix_df.columns = FEATURE_NAMES\n",
        "\n",
        "X = feat_matrix_df.iloc[:,:16].copy()\n",
        "\n",
        "#y = df['Species'].copy()\n",
        "\n",
        "# will use this to get a vector of only the labels (gestures) for comparison with predicted gestures\n",
        "y = feat_matrix_df['Gestures'].copy()\n",
        "\n",
        "#print out first 5 rows to see if the format is correct\n",
        "#X.head()\n",
        "#y\n",
        "#rest_feat_df\n",
        "feat_matrix_df"
      ],
      "metadata": {
        "id": "Xu0rxGRZ5LDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from LDA tutorial\n",
        "  #define model\n",
        "model = LDA() \n",
        "  #define model evaluation method (k-fold cross validation, repeat 10 times with shuffling data)\n",
        "cv = KFold(n_splits=200, shuffle=False, random_state=None) #no shuffling version of 200-fold cross-validation\n",
        "#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=1)\n",
        "  #evaluate model\n",
        "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  #summarize result: average accuracy across the 10 repeats of 50-fold cross-validation\n",
        "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n"
      ],
      "metadata": {
        "id": "NHB6Uc4nORVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from LDA tutorial\n",
        "# make a prediction with the lda model\n",
        "  #fit model\n",
        "model.fit(X, y)\n",
        "\n",
        "  #define new data\n",
        "#setosa = [5.1, 3.3, 1.7, 0.5] #expected class: 0\n",
        "#versicolor = [5.9, 3.0, 4.2, 1.5] #expected class: 1\n",
        "#virginica = [6.9, 3.1, 5.4, 2.1] #expected class: 2\n",
        "\n",
        "rest = X.iloc[55,:].copy() #expected class: 0; predicted 0\n",
        "#rest = X.iloc[67,:].copy() #expected class: 0; predicted 4\n",
        "\n",
        "handclose = X.iloc[250,:].copy() #expected class: 1; predicted 1\n",
        "\n",
        "#handopen = X.iloc[467,:].copy() #expected class: 2; predicted 3\n",
        "handopen = X.iloc[488,:].copy() #expected class: 2; predicted 2\n",
        "\n",
        "pointindex = X.iloc[675,:].copy() #expected class: 3; predicted 3\n",
        "\n",
        "devilhorns = X.iloc[867,:].copy() #expected class: 4; predicted 2\n",
        "#devilhorns = X.iloc[834,:].copy() #expected class: 4; predicted 4\n",
        "\n",
        "  #expected classes\n",
        "y_exp = y[55] \n",
        "#y_exp = y[67] \n",
        "\n",
        "#y_exp = y[250]\n",
        "\n",
        "#y_exp = y[467]\n",
        "#y_exp = y[488]\n",
        "\n",
        "#y_exp = y[675] \n",
        "\n",
        "#y_exp = y[867] \n",
        "#y_exp = y[834]\n",
        "\n",
        "  #make a prediction\n",
        "prediction = model.predict([rest.to_numpy()]) \n",
        "#prediction = model.predict([handclose.to_numpy()]) \n",
        "#prediction = model.predict([handopen.to_numpy()]) \n",
        "#prediction = model.predict([pointindex.to_numpy()]) \n",
        "#prediction = model.predict([devilhorns.to_numpy()]) \n",
        "\n",
        "  #summarize prediction\n",
        "print('Expected Class: %d' % y_exp)\n",
        "print('Predicted Class: %d' % prediction)\n"
      ],
      "metadata": {
        "id": "P7nkQBYuVDnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use test set to evaluate accuracy of model\n",
        "test_df = pd.read_csv(io.BytesIO(uploaded['test_data.csv']))\n",
        "test_df.columns = FEATURE_NAMES\n",
        "x_data_df = test_df.iloc[:,:16].copy()\n",
        "x_data = x_data_df.to_numpy()\n",
        "#x_data_df.head()\n",
        "\n",
        "y_data_df = test_df['Gestures'].copy()\n",
        "y_data = y_data_df.to_numpy()\n",
        "\n",
        "#print('%d' % model.predict([x_data[2]]))\n",
        "#for printing model's accuracy on test set\n",
        "acc = 0\n",
        "pred_array = []\n",
        "#y_data_df.head()\n",
        "for i in range(0,len(x_data)): \n",
        "   pred = '%d' % model.predict([x_data[i]])\n",
        "   pred_array.append(pred)\n",
        "   if int(pred_array[i]) == y_data[i]:\n",
        "     acc += 1\n",
        "\n",
        "#int(pred_array[0])\n",
        "print('Accuracy on Test Set: %d%%' % acc)\n"
      ],
      "metadata": {
        "id": "4l-mSWIPr1tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#output confusion matrix for test data\n",
        "y_pred = model.predict(x_data_df)\n",
        "cf_matrix = confusion_matrix(y_data_df,y_pred)\n",
        "print(cf_matrix)"
      ],
      "metadata": {
        "id": "DOMQdzyd-B_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert cf_matrix to heat_map for better visual\n",
        "import seaborn as sns\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Test Set Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "#ax.xaxis.set_ticklabels(['False','True'])\n",
        "#ax.yaxis.set_ticklabels(['False','True'])\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X1G_y-W9ADQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for loading test data to check model's prediction\n",
        "rest_test_df = pd.read_csv(io.BytesIO(uploaded['rest_test.csv']))\n",
        "handclose_test_df = pd.read_csv(io.BytesIO(uploaded['handclose_test.csv']))\n",
        "handopen_test_df = pd.read_csv(io.BytesIO(uploaded['handopen_test.csv']))\n",
        "pointindex_test_df = pd.read_csv(io.BytesIO(uploaded['pointindex_test.csv']))\n",
        "devilhorns_test_df = pd.read_csv(io.BytesIO(uploaded['devilhorns_test.csv']))\n",
        "\n",
        "rest_test_df.columns = FEATURE_NAMES\n",
        "handclose_test_df.columns = FEATURE_NAMES\n",
        "handopen_test_df.columns = FEATURE_NAMES\n",
        "pointindex_test_df.columns = FEATURE_NAMES\n",
        "devilhorns_test_df.columns = FEATURE_NAMES\n",
        "\n",
        "#store features of each gesture from respective files\n",
        "rx_data_df = rest_test_df.iloc[:,:16].copy()\n",
        "rx_data = rx_data_df.to_numpy()\n",
        "\n",
        "hcx_data_df = handclose_test_df.iloc[:,:16].copy()\n",
        "hcx_data = hcx_data_df.to_numpy()\n",
        "\n",
        "hox_data_df = handopen_test_df.iloc[:,:16].copy()\n",
        "hox_data = hox_data_df.to_numpy()\n",
        "\n",
        "pix_data_df = pointindex_test_df.iloc[:,:16].copy()\n",
        "pix_data = pix_data_df.to_numpy()\n",
        "\n",
        "dhx_data_df = devilhorns_test_df.iloc[:,:16].copy()\n",
        "dhx_data = dhx_data_df.to_numpy()\n",
        "\n",
        "#store gesture labels from respective files\n",
        "ry_data_df = rest_test_df['Gestures'].copy()\n",
        "ry_data = ry_data_df.to_numpy()\n",
        "\n",
        "hcy_data_df = handclose_test_df['Gestures'].copy()\n",
        "hcy_data = hcy_data_df.to_numpy()\n",
        "\n",
        "hoy_data_df = handopen_test_df['Gestures'].copy()\n",
        "hoy_data = hoy_data_df.to_numpy()\n",
        "\n",
        "piy_data_df = pointindex_test_df['Gestures'].copy()\n",
        "piy_data = piy_data_df.to_numpy()\n",
        "\n",
        "dhy_data_df = devilhorns_test_df['Gestures'].copy()\n",
        "dhy_data = dhy_data_df.to_numpy()\n"
      ],
      "metadata": {
        "id": "1RQ9rf6c7rdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for printing out mostly likely prediction\n",
        "r = 0\n",
        "hc = 0\n",
        "ho = 0\n",
        "pi = 0\n",
        "dh = 0\n",
        "\n",
        "#indicate which gesture you are testing for\n",
        "feature_test_data = hox_data\n",
        "#label_test_data = ry_data\n",
        "\n",
        "gesture_array = []\n",
        "for i in range(0,len(feature_test_data)): \n",
        "   pred = '%d' % model.predict([feature_test_data[i]])\n",
        "   gesture_array.append(pred)\n",
        "   if int(gesture_array[i]) == 0:\n",
        "     r += 1\n",
        "   if int(gesture_array[i]) == 1:\n",
        "     hc += 1\n",
        "   if int(gesture_array[i]) == 2:\n",
        "     ho += 1\n",
        "   if int(gesture_array[i]) == 3:\n",
        "     pi += 1\n",
        "   if int(gesture_array[i]) == 4:\n",
        "     dh += 1\n",
        "\n",
        "amount = [r,hc,ho,pi,dh]\n",
        "#int(pred_array[0])\n",
        "print(amount)\n",
        "print('Predicted gesture: %d' % np.argmax(amount))"
      ],
      "metadata": {
        "id": "gbC7nSNZ_CbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use pip install pySerial\n",
        "!pip install PySerial\n",
        "\n",
        "import serial\n",
        "import serial.tools.list_ports\n",
        "\n",
        "import bokeh.layouts\n",
        "import bokeh.models\n",
        "import bokeh.io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOUf7B8Jjx-a",
        "outputId": "4fadd61b-32b5-4ef6-d2e6-6c627f18130a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PySerial in /usr/local/lib/python3.7/dist-packages (3.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ports = serial.tools.list_ports.comports()\n",
        "\n",
        "# Take a look\n",
        "ports"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SRRuPIwHPa_",
        "outputId": "89b2be98-533c-4c56-80f4-774b688e343f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stream in data from serial port and convert it to a numpy array\n",
        "\n",
        "port = 'COM3'\n",
        "baud = 115200\n",
        "byte = 8\n",
        "time = 2\n",
        "stop = serial.STOPBITS_ONE\n",
        "\n",
        "serialPort = serial.Serial(port = port, baudrate = baud, bytesize = byte, timeout = time, stopbits = stop)\n",
        "\n",
        "serialString = \"\"  # Used to hold data coming over UART\n",
        "\n",
        "while(1):\n",
        "\n",
        "    # Wait until there is data waiting in the serial buffer\n",
        "    if(serialPort.in_waiting > 0):\n",
        "        # Open the serial port; prevents other processes from accessing it \n",
        "        serialPort.open()\n",
        "\n",
        "        # Read data out of the buffer until a carriage return / new line is found\n",
        "        serialString = serialPort.readline()\n",
        "\n",
        "        # Print the contents of the serial data\n",
        "        print(serialString.decode('Ascii'))\n",
        "\n",
        "        serialPort.write('%d' % prediction)\n",
        "\n",
        "#feed each array into lda model to classify gesture\n",
        "\n",
        "#record those gestures in a numpy array\n",
        "\n",
        "#after 10? sets of features classified, output the gesture that occurs the most to bluetooth UART?"
      ],
      "metadata": {
        "id": "rkVO2ZsljBzX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "9eb2f226-be14-4424-e512-5f4b4349b569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SerialException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/serial/serialposix.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mportstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mO_RDWR\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mO_NOCTTY\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mO_NONBLOCK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'COM3'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSerialException\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5667f007a252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTOPBITS_ONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mserialPort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaudrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytesize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbyte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopbits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mserialString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m  \u001b[0;31m# Used to hold data coming over UART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/serial/serialutil.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, port, baudrate, bytesize, parity, stopbits, timeout, xonxoff, rtscts, write_timeout, dsrdtr, inter_byte_timeout, exclusive, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;31m#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/serial/serialposix.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mSerialException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"could not open port {}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_port\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;31m#~ fcntl.fcntl(self.fd, fcntl.F_SETFL, 0)  # set blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSerialException\u001b[0m: [Errno 2] could not open port COM3: [Errno 2] No such file or directory: 'COM3'"
          ]
        }
      ]
    }
  ]
}